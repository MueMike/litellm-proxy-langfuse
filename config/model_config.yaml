# Model-specific configurations and pricing

models:
  # OpenAI GPT-4
  gpt-4-turbo-preview:
    max_tokens: 4096
    context_window: 128000
    supports_vision: false
    supports_function_calling: true
    pricing:
      prompt_tokens_per_1k: 0.01
      completion_tokens_per_1k: 0.03
    
  gpt-4:
    max_tokens: 8192
    context_window: 8192
    supports_vision: false
    supports_function_calling: true
    pricing:
      prompt_tokens_per_1k: 0.03
      completion_tokens_per_1k: 0.06
    
  gpt-4-32k:
    max_tokens: 32768
    context_window: 32768
    supports_vision: false
    supports_function_calling: true
    pricing:
      prompt_tokens_per_1k: 0.06
      completion_tokens_per_1k: 0.12

  # OpenAI GPT-3.5
  gpt-3.5-turbo:
    max_tokens: 4096
    context_window: 16385
    supports_vision: false
    supports_function_calling: true
    pricing:
      prompt_tokens_per_1k: 0.0015
      completion_tokens_per_1k: 0.002
      
  gpt-3.5-turbo-16k:
    max_tokens: 16384
    context_window: 16384
    supports_vision: false
    supports_function_calling: true
    pricing:
      prompt_tokens_per_1k: 0.003
      completion_tokens_per_1k: 0.004

  # Anthropic Claude 3
  claude-3-opus-20240229:
    max_tokens: 4096
    context_window: 200000
    supports_vision: true
    supports_function_calling: true
    pricing:
      prompt_tokens_per_1k: 0.015
      completion_tokens_per_1k: 0.075
      
  claude-3-sonnet-20240229:
    max_tokens: 4096
    context_window: 200000
    supports_vision: true
    supports_function_calling: true
    pricing:
      prompt_tokens_per_1k: 0.003
      completion_tokens_per_1k: 0.015
      
  claude-3-haiku-20240307:
    max_tokens: 4096
    context_window: 200000
    supports_vision: true
    supports_function_calling: true
    pricing:
      prompt_tokens_per_1k: 0.00025
      completion_tokens_per_1k: 0.00125

  # Anthropic Claude 2
  claude-2.1:
    max_tokens: 4096
    context_window: 200000
    supports_vision: false
    supports_function_calling: false
    pricing:
      prompt_tokens_per_1k: 0.008
      completion_tokens_per_1k: 0.024

  claude-2.0:
    max_tokens: 4096
    context_window: 100000
    supports_vision: false
    supports_function_calling: false
    pricing:
      prompt_tokens_per_1k: 0.008
      completion_tokens_per_1k: 0.024

# Provider-specific settings
providers:
  openai:
    default_max_retries: 3
    timeout: 600
    supports_streaming: true
    
  anthropic:
    default_max_retries: 3
    timeout: 600
    supports_streaming: true
    
  azure:
    default_max_retries: 3
    timeout: 600
    supports_streaming: true
    
  bedrock:
    default_max_retries: 2
    timeout: 300
    supports_streaming: true
    
  vertex_ai:
    default_max_retries: 3
    timeout: 600
    supports_streaming: true

# Rate limiting per model (requests per minute)
rate_limits:
  gpt-4-turbo-preview: 500
  gpt-4: 500
  gpt-3.5-turbo: 3500
  claude-3-opus-20240229: 1000
  claude-3-sonnet-20240229: 2000
  claude-3-haiku-20240307: 4000
