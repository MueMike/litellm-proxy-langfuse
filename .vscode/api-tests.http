# ============================================================================
# LiteLLM Proxy API Tests - VSCode REST Client
# ============================================================================
# Install the "REST Client" extension (humao.rest-client) to use this file
# Click "Send Request" above each request to execute it
# Results appear in a split pane to the right
# ============================================================================

# Environment Variables
@baseUrl = http://localhost:8000
@apiKey = dummy-key-if-auth-disabled
@userId = vscode-tester
@sessionId = rest-client-session-001

# ============================================================================
# Health and System Checks
# ============================================================================

### Health Check
GET {{baseUrl}}/health
Content-Type: application/json

###

### List Available Models
GET {{baseUrl}}/v1/models
Content-Type: application/json

# ============================================================================
# Chat Completion Requests
# ============================================================================

### Simple Chat Completion with GPT-5 Mini (Latest Fast Model)
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: {{sessionId}}

{
  "model": "gpt-5-mini",
  "messages": [
    {
      "role": "user",
      "content": "Write a simple Python function to check if a number is prime."
    }
  ],
  "max_tokens": 500,
  "temperature": 0.7
}

###

### Chat Completion with GPT-5 and Metadata (Latest Best Model)
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: {{sessionId}}

{
  "model": "gpt-5",
  "messages": [
    {
      "role": "system",
      "content": "You are an expert Python developer."
    },
    {
      "role": "user",
      "content": "Explain the difference between list comprehension and generator expression in Python."
    }
  ],
  "max_tokens": 800,
  "temperature": 0.5,
  "metadata": {
    "task_type": "explanation",
    "language": "python",
    "topic": "comprehensions"
  }
}

###

### Code Generation with Claude Sonnet 4.5 (Best for Coding)
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: {{sessionId}}

{
  "model": "claude-sonnet-4-5",
  "messages": [
    {
      "role": "system",
      "content": "You are an expert JavaScript developer."
    },
    {
      "role": "user",
      "content": "Write a React hook for debouncing user input."
    }
  ],
  "max_tokens": 600,
  "temperature": 0.7,
  "metadata": {
    "task_type": "code_generation",
    "language": "javascript",
    "framework": "react"
  }
}

###

### Multi-turn Conversation
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: conversation-multi-turn

{
  "model": "gpt-5",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful coding assistant."
    },
    {
      "role": "user",
      "content": "What is dependency injection?"
    },
    {
      "role": "assistant",
      "content": "Dependency injection is a design pattern where objects receive their dependencies from external sources rather than creating them internally."
    },
    {
      "role": "user",
      "content": "Can you show me an example in Python?"
    }
  ],
  "max_tokens": 800,
  "temperature": 0.7
}

###

### Code Review Request
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: code-review-session

{
  "model": "gpt-5",
  "messages": [
    {
      "role": "system",
      "content": "You are an expert code reviewer. Provide constructive feedback on code quality, potential bugs, and best practices."
    },
    {
      "role": "user",
      "content": "Review this code:\n\n```python\ndef calculate_total(items):\n    total = 0\n    for i in items:\n        total = total + i['price'] * i['quantity']\n    return total\n```"
    }
  ],
  "max_tokens": 1000,
  "temperature": 0.3,
  "metadata": {
    "task_type": "code_review",
    "language": "python"
  }
}

###

### Unit Test Generation
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: unittest-generation

{
  "model": "claude-sonnet-4-5",
  "messages": [
    {
      "role": "system",
      "content": "You are an expert at writing comprehensive unit tests using pytest."
    },
    {
      "role": "user",
      "content": "Generate pytest tests for this function:\n\n```python\ndef validate_email(email: str) -> bool:\n    import re\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return bool(re.match(pattern, email))\n```"
    }
  ],
  "max_tokens": 1200,
  "temperature": 0.3,
  "metadata": {
    "task_type": "unit_test_generation",
    "language": "python",
    "framework": "pytest"
  }
}

###

### Bug Fix Suggestion
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: bug-fix-session

{
  "model": "claude-sonnet-4-5",
  "messages": [
    {
      "role": "system",
      "content": "You are a debugging expert. Identify bugs and suggest fixes."
    },
    {
      "role": "user",
      "content": "This code has a bug. Find it and suggest a fix:\n\n```python\ndef find_max(numbers):\n    max_num = 0\n    for num in numbers:\n        if num > max_num:\n            max_num = num\n    return max_num\n```"
    }
  ],
  "max_tokens": 800,
  "temperature": 0.3,
  "metadata": {
    "task_type": "bug_fix",
    "language": "python"
  }
}

###

### Documentation Generation
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: docs-generation

{
  "model": "gpt-5",
  "messages": [
    {
      "role": "system",
      "content": "You are a technical writer. Generate clear and comprehensive documentation."
    },
    {
      "role": "user",
      "content": "Write docstrings for this function:\n\n```python\ndef merge_sorted_lists(list1, list2):\n    result = []\n    i, j = 0, 0\n    while i < len(list1) and j < len(list2):\n        if list1[i] < list2[j]:\n            result.append(list1[i])\n            i += 1\n        else:\n            result.append(list2[j])\n            j += 1\n    result.extend(list1[i:])\n    result.extend(list2[j:])\n    return result\n```"
    }
  ],
  "max_tokens": 600,
  "temperature": 0.5,
  "metadata": {
    "task_type": "documentation",
    "language": "python"
  }
}

###

# ============================================================================
# Streaming Requests
# ============================================================================

### Streaming Chat Completion
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: streaming-session

{
  "model": "gpt-5-mini",
  "messages": [
    {
      "role": "user",
      "content": "Count from 1 to 10 slowly."
    }
  ],
  "stream": true,
  "max_tokens": 100
}

###

# ============================================================================
# Performance and Cost Testing
# ============================================================================

### Fast Model - Claude Haiku 4.5
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: performance-test

{
  "model": "claude-haiku-4-5",
  "messages": [
    {
      "role": "user",
      "content": "What is 2 + 2?"
    }
  ],
  "max_tokens": 50
}

###

### Check Prometheus Metrics
GET http://localhost:9090/metrics

###

# ============================================================================
# Error Testing
# ============================================================================

### Invalid Model Name
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: error-test

{
  "model": "invalid-model-name",
  "messages": [
    {
      "role": "user",
      "content": "This should fail."
    }
  ]
}

###

### Empty Messages Array
POST {{baseUrl}}/v1/chat/completions
Content-Type: application/json
X-User-ID: {{userId}}
X-Session-ID: error-test

{
  "model": "gpt-3.5-turbo",
  "messages": []
}

###

# ============================================================================
# LangFuse Tracing Verification
# ============================================================================
# After running these requests:
# 1. Go to your LangFuse dashboard (https://cloud.langfuse.com)
# 2. Navigate to your project
# 3. View "Traces" section
# 4. Filter by Session ID: "rest-client-session-001"
# 5. You should see all the requests with:
#    - Full request/response details
#    - Token usage and costs
#    - Latency metrics
#    - Custom metadata tags
# ============================================================================
